#importing the libraries
import numpy as np # linear algebra
import pandas as pd # data processing
import matplotlib.pyplot as plt # data visualization
import seaborn as sns # advanced data visualization

from sklearn.model_selection import train_test_split # split data into train and test
from sklearn.preprocessing import MinMaxScaler # scale the data between 0 - 1
from tensorflow.keras.models import Sequential # initiate the mode 
from tensorflow.keras.layers import Dense, Activation, Dropout # add the layers
from tensorflow.keras.optimizers import Adam # optimizer 

from tensorflow.keras.callbacks import EarlyStopping # Early Stopping

from sklearn.metrics import classification_report,confusion_matrix # Model Evaluation 

df = pd.read_csv('data.csv')
df.describe().round(2).transpose()
df = df.drop('Unnamed: 32', axis = 1)
df['diagnosis'] = df['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)

X = df.drop('diagnosis', axis = 1).values
y = df['diagnosis'].values 

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)

# intiate the scaler 
scaler = MinMaxScaler()
# fit the scaler and scale training data 
X_train= scaler.fit_transform(X_train)
# scale the test data 
X_test = scaler.transform(X_test)

# build model architecture
model = Sequential()
model.add(Dense(30,activation='relu'))
model.add(Dense(15,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

# compile the model
model.compile(optimizer='adam',loss='binary_crossentropy');

# fit the model
model.fit(x=X_train,y=y_train,
          validation_data=(X_test,y_test),epochs=600)

# compare train and validation loss 
model_loss = pd.DataFrame(model.history.history)
plt.figure(figsize=(8,4), dpi = 100)
plt.plot(model_loss)
plt.show()

# build model architecture
model = Sequential()
model.add(Dense(30,activation='relu'))
model.add(Dense(15,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

# compile the model
model.compile(optimizer='adam',loss='binary_crossentropy');

# Define Early Stopping 
early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)

# fit the model
model.fit(x=X_train,y=y_train,
          validation_data=(X_test,y_test),epochs=600, callbacks = [early_stop])

# compare train and validation loss 
model_loss = pd.DataFrame(model.history.history)
plt.figure(figsize=(8,4), dpi = 100)
plt.plot(model_loss)
plt.show()

# build model architecture
model = Sequential()
model.add(Dense(30,activation='relu'))
model.add(Dropout(0.5)) # Drop Out Layer 
model.add(Dense(15,activation='relu'))
model.add(Dropout(0.5)) # Drop Out Layer
model.add(Dense(1,activation='sigmoid'))

# compile the model
model.compile(optimizer='adam',loss='binary_crossentropy');

# fit the model
model.fit(x=X_train,y=y_train,
          validation_data=(X_test,y_test),epochs=600, callbacks = [early_stop])

# compare train and validation loss 
model_loss = pd.DataFrame(model.history.history)
plt.figure(figsize=(8,4), dpi = 100)
plt.plot(model_loss)
plt.show()

# Predictions
y_pred = model.predict(X_test)
predictions = np.round(y_pred).astype(int)

# Classification Report 
print(classification_report(y_test,predictions))
print(predictions)
